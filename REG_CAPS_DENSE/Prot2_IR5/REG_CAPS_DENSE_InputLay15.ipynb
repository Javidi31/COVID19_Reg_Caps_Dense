{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"REG_CAPS_DENSE_InputLay15.ipynb","provenance":[{"file_id":"1Fluv_7ZQD2cet7QCFRPE91a_bSmXCfR9","timestamp":1615164871330},{"file_id":"1FnmVF8sKoRNtoeyHGIw09KJO5FaW_cLm","timestamp":1614597326958},{"file_id":"1cssP_UYQcJfjzKOEO-uAgnR40tc4X6jB","timestamp":1613345298429},{"file_id":"1L6YlyeLrvP1ER4cWjFDyeSE47fLYgoeF","timestamp":1568283464321},{"file_id":"1dBGVKT5pZ9tBbryRalYyVI2ToSt8yeGP","timestamp":1566140403317}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"021a6jde9jyS"},"source":["from __future__ import division, print_function, unicode_literals"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4tcd2dXf9jyZ","executionInfo":{"status":"ok","timestamp":1617790574553,"user_tz":-60,"elapsed":9148,"user":{"displayName":"capsule network","photoUrl":"","userId":"11269108799922645077"}},"outputId":"b423dcf9-8550-4a17-8716-35263f7d7206"},"source":["%tensorflow_version 1.x\n","%matplotlib inline\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import pickle\n","import csv\n","import numpy as np\n","import tensorflow as tf\n","import pandas as pd\n","import httplib2\n","import os\n","import requests\n","from PIL import Image\n","import time\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ajKy54IdTCAc","executionInfo":{"status":"ok","timestamp":1617790641115,"user_tz":-60,"elapsed":75626,"user":{"displayName":"capsule network","photoUrl":"","userId":"11269108799922645077"}},"outputId":"57d04f8f-7442-4349-9e5e-b027d872ff30"},"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive/\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"s6hSUPmL9jyl"},"source":["tf.reset_default_graph()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u1_v5zKf9jys"},"source":["np.random.seed(42)\n","tf.set_random_seed(42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zglg8ZtV9jyx"},"source":["# Load Data\n"]},{"cell_type":"code","metadata":{"id":"M5Wfh8Zy9jy2"},"source":["# !unzip 'gdrive/My Drive/Covid19/Features_Prot2_Lay17.zip' -d 'gdrive/My Drive/Covid19/Features_Prot2_Lay17'\n","# !unzip 'gdrive/My Drive/Covid19/Features_Prot2_Lay15.zip' -d 'gdrive/My Drive/Covid19/Features_Prot2_Lay15'\n","\n","# count of data on each folder\n","# !ls  \"gdrive/My Drive/Covid19/Features_Prot2_Lay15/Features_Prot2_Lay15\" | wc -l"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"61OTz3GRDnNS"},"source":["checkpoint_path = 'gdrive/My Drive/Covid19/codes/REG_CAPS_DENSE/Prot1/'\n","\n","image_size = 28\n","img_channel = 32\n","all_img_no = 19685\n","tr_img_no = 17716\n","ts_img_no = 1969\n","\n","  pathMain = '/content/gdrive/MyDrive/Covid19/Features/'\n","\n","from tqdm.notebook import tqdm\n","if False:\n","  cnt = 0\n","  All = np.zeros( shape = (all_img_no,image_size,image_size,img_channel) )\n","  for i in tqdm(range(tr_img_no)):\n","    path = pathMain + 'FeaturesTr/'\n","    path = path +  str(i)+ 'OutTr_lay15.pckl'  \n","    with open(path, 'rb') as f:\n","      All[cnt,:,:,:] = pickle.load(f)\n","    cnt +=1\n","\n","  with open(pathMain+'TargetTrain.pckl', 'rb') as f:\n","    Tr_label = pickle.load(f)\n","  Tr_label = np.argmax(Tr_label , axis = 1)\n","  \n","  for i in tqdm(range(ts_img_no)):\n","    path = pathMain + 'FeaturesTe/'\n","    path = path +  str(i)+ 'OutTs_lay15.pckl'  \n","    with open(path, 'rb') as f:\n","      All[cnt,:,:,:] = pickle.load(f)\n","    cnt +=1\n","\n","  with open(pathMain+'TargetTest.pckl', 'rb') as f:\n","    Ts_label = pickle.load(f)\n","  Ts_label = np.argmax(Ts_label , axis = 1)\n","\n","  All_label = np.concatenate((Tr_label,Ts_label),axis=0)\n","  with open(pathMain + 'DS.pckl', 'wb') as f:\n","    pickle.dump([All, All_label], f)\n","\n","else:\n","  with open(pathMain + 'DS.pckl', 'rb') as f:\n","      All, All_label = pickle.load(f)\n","\n","# from sklearn.model_selection import train_test_split\n","# Train, Test, Train_label, Test_label = train_test_split(All, All_label, test_size=0.25, random_state=101, stratify=All_label)\n","\n","# pct_no = 250\n","# Train_pct = Train[Train_label==0]  \n","# Train = Train[Train_label != 0]\n","# y_train_pct = Train_label[Train_label==0]\n","# Train_label = Train_label[Train_label != 0]\n","# Train_pct = Train_pct[:pct_no]\n","# y_train_pct = y_train_pct[:pct_no]\n","\n","# Train = np.concatenate((Train,Train_pct),axis=0)\n","# Train_label = np.concatenate((Train_label,y_train_pct),axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A-jGcR-HtWQ9"},"source":["num_class = len(set(All_label))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hvZHWQuY9jzV"},"source":["X = tf.placeholder(shape=[None, image_size, image_size, img_channel], dtype=tf.float32, name=\"X\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rKBfgs2S9jzZ"},"source":["# Primary Capsules"]},{"cell_type":"markdown","metadata":{"id":"AhxauLMd9jzc"},"source":["The first layer will be composed of 32 maps of 6Ã—6 capsules each, where each capsule will output an 8D activation vector:"]},{"cell_type":"code","metadata":{"id":"jVG3CglH9jzf"},"source":["caps1_n_maps = 32\n","caps1_n_caps = caps1_n_maps * 6 * 6  # 1152 primary capsules  (FOR MNIST)\n","# caps1_n_caps = caps1_n_maps * 11 * 11  # 41472 primary capsules    (FOR Cedar)\n","caps1_n_dims = 8"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yl7xE4Pz9jzo"},"source":["conv1_params = {\n","    \"filters\": 256,\n","    \"kernel_size\": 9,\n","    \"strides\": 1,\n","    \"padding\": \"valid\",\n","    \"activation\": tf.nn.relu,\n","}\n","\n","conv2_params = {\n","    \"filters\": caps1_n_maps * caps1_n_dims, # 256 convolutional filters\n","    \"kernel_size\": 9,\n","    \"strides\": 2,\n","    \"padding\": \"valid\",\n","    \"activation\": tf.nn.relu\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QfzIVmcK9jzy","executionInfo":{"status":"ok","timestamp":1617790720775,"user_tz":-60,"elapsed":155108,"user":{"displayName":"capsule network","photoUrl":"","userId":"11269108799922645077"}},"outputId":"f80a3567-1216-4072-8738-23747e722862"},"source":["conv1 = tf.layers.conv2d(X, name=\"conv1\", **conv1_params)\n","conv2 = tf.layers.conv2d(conv1, name=\"conv2\", **conv2_params)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-12-3a2df923b7cc>:1: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.keras.layers.Conv2D` instead.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"165a6xB49jz4"},"source":["caps1_raw = tf.reshape(conv2, [-1, caps1_n_caps, caps1_n_dims],\n","                       name=\"caps1_raw\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O2LYGO7M9jz9"},"source":["def squash(s, axis=-1, epsilon=1e-7, name=None):\n","    with tf.name_scope(name, default_name=\"squash\"):\n","        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n","                                     keep_dims=True)\n","        safe_norm = tf.sqrt(squared_norm + epsilon)\n","        squash_factor = squared_norm / (1. + squared_norm)\n","        unit_vector = s / safe_norm\n","        return squash_factor * unit_vector"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VX94m3UL9j0D","executionInfo":{"status":"ok","timestamp":1617790720781,"user_tz":-60,"elapsed":155023,"user":{"displayName":"capsule network","photoUrl":"","userId":"11269108799922645077"}},"outputId":"6000725e-84aa-4577-f0c4-1fd353ced93c"},"source":["caps1_output = squash(caps1_raw, name=\"caps1_output\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-14-8037c6cbfef1>:4: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"d8sCULMD9j0I"},"source":["# Digit Capsules"]},{"cell_type":"markdown","metadata":{"id":"Su5YiBRN9j0K"},"source":["## Compute the Predicted Output Vectors"]},{"cell_type":"code","metadata":{"id":"pmJ9SqMj9j0O"},"source":["caps2_n_caps = num_class\n","caps2_n_dims = 16"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TIiRtrmp9j0i"},"source":["init_sigma = 0.1\n","\n","W_init = tf.random_normal(\n","    shape=(1, caps1_n_caps, caps2_n_caps, caps2_n_dims, caps1_n_dims),\n","    stddev=init_sigma, dtype=tf.float32, name=\"W_init\")\n","W = tf.Variable(W_init, name=\"W\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZrpBffKM9j0o"},"source":["batch_size = tf.shape(X)[0]\n","W_tiled = tf.tile(W, [batch_size, 1, 1, 1, 1], name=\"W_tiled\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kplr4-ye9j0v"},"source":["caps1_output_expanded = tf.expand_dims(caps1_output, -1,\n","                                       name=\"caps1_output_expanded\")\n","caps1_output_tile = tf.expand_dims(caps1_output_expanded, 2,\n","                                   name=\"caps1_output_tile\")\n","caps1_output_tiled = tf.tile(caps1_output_tile, [1, 1, caps2_n_caps, 1, 1],\n","                             name=\"caps1_output_tiled\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"es9xwpUG9j08"},"source":["caps2_predicted = tf.matmul(W_tiled, caps1_output_tiled,\n","                            name=\"caps2_predicted\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dTQ5jQ6I9j1U"},"source":["## Routing by agreement"]},{"cell_type":"code","metadata":{"id":"K-E1PwAX9j1Y"},"source":["raw_weights = tf.zeros([batch_size, caps1_n_caps, caps2_n_caps, 1, 1],\n","                       dtype=np.float32, name=\"raw_weights\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YYUkeQVy9j1f"},"source":["### Round 1"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vt7pJ0Ro9j1i","executionInfo":{"status":"ok","timestamp":1617790721098,"user_tz":-60,"elapsed":155223,"user":{"displayName":"capsule network","photoUrl":"","userId":"11269108799922645077"}},"outputId":"20b29f5d-3b0e-4b32-9feb-2d3c1ddf0f09"},"source":["routing_weights = tf.nn.softmax(raw_weights, dim=2, name=\"routing_weights\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-22-86a489ae595f>:1: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n","Instructions for updating:\n","dim is deprecated, use axis instead\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9AIuawod9j1o"},"source":["weighted_predictions = tf.multiply(routing_weights, caps2_predicted,\n","                                   name=\"weighted_predictions\")\n","weighted_sum = tf.reduce_sum(weighted_predictions, axis=1, keep_dims=True,\n","                             name=\"weighted_sum\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uq6dKvqN9j1v"},"source":["caps2_output_round_1 = squash(weighted_sum, axis=-2,\n","                              name=\"caps2_output_round_1\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ne_0Ggym9j19"},"source":["### Round 2"]},{"cell_type":"code","metadata":{"id":"hVVNoZn39j2O"},"source":["caps2_output_round_1_tiled = tf.tile(\n","    caps2_output_round_1, [1, caps1_n_caps, 1, 1, 1],\n","    name=\"caps2_output_round_1_tiled\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1KVJjzim9j2a"},"source":["agreement = tf.matmul(caps2_predicted, caps2_output_round_1_tiled,\n","                      transpose_a=True, name=\"agreement\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mqxkx8AZ9j2i"},"source":["raw_weights_round_2 = tf.add(raw_weights, agreement,\n","                             name=\"raw_weights_round_2\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oJGXFcJB9j2q"},"source":["The rest of round 2 is the same as in round 1:"]},{"cell_type":"code","metadata":{"id":"NABrArjk9j2s"},"source":["routing_weights_round_2 = tf.nn.softmax(raw_weights_round_2,\n","                                        dim=2,\n","                                        name=\"routing_weights_round_2\")\n","weighted_predictions_round_2 = tf.multiply(routing_weights_round_2,\n","                                           caps2_predicted,\n","                                           name=\"weighted_predictions_round_2\")\n","weighted_sum_round_2 = tf.reduce_sum(weighted_predictions_round_2,\n","                                     axis=1, keep_dims=True,\n","                                     name=\"weighted_sum_round_2\")\n","caps2_output_round_2 = squash(weighted_sum_round_2,\n","                              axis=-2,\n","                              name=\"caps2_output_round_2\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HqaGWi4y9j2z"},"source":["caps2_output = caps2_output_round_2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cGQ4INwv9j3M"},"source":["# Estimated Class Probabilities (Length)"]},{"cell_type":"code","metadata":{"id":"lGIVUuH19j3N"},"source":["def safe_norm(s, axis=-1, epsilon=1e-7, keep_dims=False, name=None):\n","    with tf.name_scope(name, default_name=\"safe_norm\"):\n","        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n","                                     keep_dims=keep_dims)\n","        return tf.sqrt(squared_norm + epsilon)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1q50GaNp9j3P"},"source":["y_proba = safe_norm(caps2_output, axis=-2, name=\"y_proba\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CzMfIwZn9j3S"},"source":["y_proba_argmax = tf.argmax(y_proba, axis=2, name=\"y_proba\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ru-B8Hhm9j3a"},"source":["y_pred = tf.squeeze(y_proba_argmax, axis=[1,2], name=\"y_pred\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UACRxGrR9j3f"},"source":["# Labels"]},{"cell_type":"code","metadata":{"id":"OgprXnYM9j3g"},"source":["y = tf.placeholder(shape=[None], dtype=tf.int64, name=\"y\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n4SUUi3m9j3i"},"source":["# Margin loss"]},{"cell_type":"code","metadata":{"id":"Zr5V1dR39j3m"},"source":["m_plus = 0.9\n","m_minus = 0.1\n","lambda_ = 0.5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iwQPxvNC9j3q"},"source":["T = tf.one_hot(y, depth=caps2_n_caps, name=\"T\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hp5BwrcJ9j35"},"source":["caps2_output_norm = safe_norm(caps2_output, axis=-2, keep_dims=True,\n","                              name=\"caps2_output_norm\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lTRul1WF9j4D"},"source":["present_error_raw = tf.square(tf.maximum(0., m_plus - caps2_output_norm),\n","                              name=\"present_error_raw\")\n","present_error = tf.reshape(present_error_raw, shape=(-1, num_class),\n","                           name=\"present_error\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-I3GjYL19j4H"},"source":["absent_error_raw = tf.square(tf.maximum(0., caps2_output_norm - m_minus),\n","                             name=\"absent_error_raw\")\n","absent_error = tf.reshape(absent_error_raw, shape=(-1, num_class),\n","                          name=\"absent_error\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LhLY3ftX9j4L"},"source":["L = tf.add(T * present_error, lambda_ * (1.0 - T) * absent_error,\n","           name=\"L\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FHW6DbEq9j4O"},"source":["\n","# C = tf.placeholder(shape=[None,1], dtype=tf.float32)\n","\n","# L_CS = tf.multiply(L , C)\n","\n","margin_loss = tf.reduce_mean(tf.reduce_sum(L, axis=1), name=\"margin_loss\")\n","# margin_loss = tf.reduce_mean(tf.reduce_sum(L_CS, axis=1), name=\"margin_loss\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ITEFuHr-9j5I"},"source":["## Final Loss"]},{"cell_type":"code","metadata":{"id":"5dAq9M8d9j5J"},"source":["alpha = 0.00001\n","\n","regularizer = tf.nn.l2_loss(W_tiled)\n","beta = 0.000001#0.000001\n","##loss = tf.add(loss_, beta * regularizer, name=\"loss\")\n","loss = tf.add(margin_loss, beta * regularizer, name=\"loss\")\n","\n","# loss_ = tf.add(margin_loss, alpha * reconstruction_loss, name=\"loss_\")\n","# regularizer = tf.nn.l2_loss(W_tiled)\n","# beta = 0.0000001\n","# loss = tf.add(loss_, beta * regularizer, name=\"loss\")\n","\n","loss_for_plot = tf.add(margin_loss, beta * regularizer / tf.cast(batch_size, tf.float32), name=\"loss\") #**"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3Wv1K5ZT9j5L"},"source":["## Accuracy"]},{"cell_type":"code","metadata":{"id":"x4MT_M-B9j5M"},"source":["correct = tf.equal(y, y_pred, name=\"correct\")\n","accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nUiNO6j19j5P"},"source":["## Training Operations"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fFMEmu-I9j5R","executionInfo":{"status":"ok","timestamp":1617790722136,"user_tz":-60,"elapsed":155782,"user":{"displayName":"capsule network","photoUrl":"","userId":"11269108799922645077"}},"outputId":"1ba0376b-e6e3-44a9-faed-16a6cca8fea0"},"source":["optimizer = tf.train.AdamOptimizer()\n","training_op = optimizer.minimize(loss, name=\"training_op\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xUsapqe19j5V"},"source":["init = tf.global_variables_initializer()\n","saver = tf.train.Saver( max_to_keep =1 , filename = 'TestName')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fs97Hkh0fbv6"},"source":["def getNextBatchTrain(batch_size):\n","  N = np.size(Train,0)\n","  idx = np.random.randint(0,N,batch_size)\n","  batchLabel = Train_label[idx]\n","  return Train[idx,:]  , batchLabel.astype('uint8')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UZOOBJFngcqD"},"source":["# def getNextBatchTest(batch_size):\n","#   N = np.size(Test,0)\n","#   idx = np.random.randint(0,N,batch_size)\n","#   batchLabel = Test_label[idx]\n","#   return Test[idx,:]  , batchLabel.astype('uint8')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WQ_O7-A69j5a"},"source":["# Training"]},{"cell_type":"code","metadata":{"id":"oFagjc5O9j5d"},"source":["# n_epochs = 100\n","# batch_size = 10\n","# restore_checkpoint = False\n","\n","# n_iterations_per_epoch = len(Train_label) // batch_size\n","# n_iterations_validation = len(Test_label)\n","# best_loss_val = np.infty\n","# checkpoint_path = \"/content/gdrive/My Drive/Dataset/covid19/\"\n","\n","# loss_trains = []\n","# with tf.Session() as sess:\n","#     if restore_checkpoint and tf.train.checkpoint_exists(checkpoint_path):\n","#         saver.restore(sess, checkpoint_path)\n","#     else:\n","#         print('not loaded!')\n","#         init.run()\n","\n","#     for epoch in range(n_epochs):\n","#       for iteration in range(1, n_iterations_per_epoch + 1):\n","#           X_batch, y_batch = getNextBatchTrain(batch_size)\n","#           # Run the training operation and measure the loss:\n","#           _, loss_train = sess.run(\n","#               [training_op, loss],\n","#               feed_dict={X: X_batch.reshape([-1, image_size, image_size, img_channel]),\n","#                           y: y_batch})\n","#           print(\"\\rIteration: {}/{} ({:.1f}%)  Loss: {:.5f}\".format(\n","#                     iteration, n_iterations_per_epoch,\n","#                     iteration * 100 / n_iterations_per_epoch,\n","#                     loss_train),\n","#                 end=\"\")\n","\n","#       loss_trains.append(loss_train)\n","#       # At the end of each epoch,\n","#       # measure the validation loss and accuracy:\n","#       loss_vals = []\n","#       acc_vals = []\n","#       y_pred_all = []\n","#       for iteration in range(1, n_iterations_validation + 1):\n","#         X_batch = Test[iteration-1:iteration] #getNextBatchTest(batch_size)\n","#         y_batch = Test_label[iteration-1:iteration].astype('uint8')\n","#         loss_val, acc_val , y_pred_sample = sess.run(\n","#                 [loss, accuracy, y_pred],\n","#                 feed_dict={X: X_batch.reshape([-1, image_size, image_size, img_channel]),\n","#                           y: y_batch})\n","#         loss_vals.append(loss_val)\n","#         acc_vals.append(acc_val)\n","#         y_pred_all.append(y_pred_sample)\n","      \n","#       print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n","#                 iteration, n_iterations_validation,\n","#                 iteration * 100 / n_iterations_validation),\n","#             end=\" \" * 10)\n","#       loss_val = np.mean(loss_vals)\n","#       acc_val = np.mean(acc_vals)\n","#       print(\"\\rEpoch: {}  Val accuracy: {:.4f}%  Loss: {:.6f}{}\".format(\n","#           epoch + 1, acc_val * 100, loss_val,\n","#           \" (improved)\" if loss_val < best_loss_val else \"\"))\n","\n","#       print(loss_train)\n","#       # And save the model if it improved: (No!)\n","#       if False:\n","#         save_path = saver.save(sess, checkpoint_path)\n","#       # if loss_val < best_loss_val:\n","#       #   # clearCheckPointFiles()\n","#       #   save_path = saver.save(sess, checkpoint_path);\n","#       #   best_loss_val = loss_val"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lXApM1gHqImC","executionInfo":{"status":"ok","timestamp":1617791923714,"user_tz":-60,"elapsed":54203,"user":{"displayName":"capsule network","photoUrl":"","userId":"11269108799922645077"}},"outputId":"136305f4-0abe-4dcb-bab6-53ef3ae7da34"},"source":["from sklearn.model_selection import KFold\n","kfold = KFold(n_splits=10, shuffle=True,random_state=101)\n","\n","checkpoint_path_main = checkpoint_path\n","\n","fold_no = 0\n","start_fold = 10\n","for train, test in kfold.split(All, All_label):\n","  fold_no += 1\n","  if start_fold > fold_no:\n","    continue\n","\n","  checkpoint_path = checkpoint_path_main + 'Fold' + str(fold_no)\n","\n","  Train = All[train]\n","  Train_label = All_label[train]\n","  Test = All[test]\n","  Test_label = All_label[test]\n","\n","  n_epochs = 20\n","  batch_size = 10\n","  restore_checkpoint = True\n","\n","  n_iterations_per_epoch = len(Train_label) // batch_size\n","  n_iterations_validation = len(Test_label) #// batch_size\n","  best_loss_val = np.infty\n","\n","  with tf.Session() as sess:\n","      if restore_checkpoint and tf.train.checkpoint_exists(checkpoint_path):\n","          saver.restore(sess, checkpoint_path)\n","          with open(checkpoint_path + 'OtherVars', 'rb') as f:\n","              acc_trains, loss_trains, acc_tests, loss_tests ,time_per_epochs, start_epoch , y_pred_all = pickle.load(f)\n","              start_epoch += 1\n","          print('\\nStarting from epoch: %.0f\\n' %(start_epoch + 1))\n","      else:\n","          print('\\nCheck point not loaded\\n')\n","          init.run()\n","          loss_trains = []\n","          acc_trains = [] \n","          loss_tests = []\n","          acc_tests = []\n","          time_per_epochs = []\n","          start_epoch = 0\n","          y_pred_all = np.zeros((n_iterations_validation,n_epochs))\n","\n","      for epoch in range(start_epoch,n_epochs):\n","          startTime = time.time()\n","          loss_train = []\n","          acc_train=[]\n","          for iteration in range(1, n_iterations_per_epoch + 1):\n","              X_batch, y_batch = getNextBatchTrain(batch_size)\n","              # CC = np.zeros((batch_size,1))\n","              # for i in range(batch_size):\n","              #   CC[i] = 1 - np.sum(Train_label == y_batch[i]) / len(Train_label)\n","              # Run the training operation and measure the loss:\n","              _, loss_train_batch,acc_train_batch = sess.run(\n","                  [training_op, loss_for_plot,accuracy],\n","                  feed_dict = {X: X_batch.reshape([-1, image_size, image_size, img_channel]),\n","                            y: y_batch})\n","              print(\"\\rIteration: {}/{} ({:.1f}%)  Loss: {:.5f}\".format(\n","                        iteration, n_iterations_per_epoch,\n","                        iteration * 100 / n_iterations_per_epoch,\n","                        loss_train_batch),\n","                    end=\"\")\n","              \n","              loss_train.append(loss_train_batch)\n","              acc_train.append(acc_train_batch)\n","\n","          end_time = time.time()\n","          time_per_epochs.append(end_time - startTime)\n","          print('\\nElapsed: %.1f' % (end_time - startTime))\n","          remainHour = (n_epochs-epoch) * (end_time - startTime)/3600\n","          print('Estimated remaining time: %.1f hours' % remainHour)\n","\n","          acc_trains.append(np.mean(acc_train))\n","          loss_trains.append(np.mean(loss_train))\n","\n","          #print(\"*****\")\n","          #print(\"loss_train:\",np.mean(loss_train)) #**        \n","          #print(\"acc_train\",np.mean(acc_train)*100) #**Javidi\n","          #print(\"*****\")\n","\n","          # At the end of each epoch,\n","          # measure the validation loss and accuracy:\n","          loss_vals = []\n","          acc_vals = []\n","          \n","          for iteration in range(1, n_iterations_validation + 1):\n","              X_batch = Test[iteration-1:iteration]\n","              y_batch = Test_label[iteration-1:iteration].astype('uint8')\n","              # CC = np.zeros((1,1))\n","              \n","              # CC[0] = 1 - np.sum(Train_label == y_batch[0]) / len(Train_label)\n","              #X_batch, y_batch = getNextBatchTest(batch_size)\n","              loss_val, acc_val , y_pred_sample = sess.run(\n","                      [loss_for_plot, accuracy , y_pred],\n","                      feed_dict={X: X_batch.reshape([-1, image_size, image_size, img_channel]),\n","                                y: y_batch})\n","\n","              loss_vals.append(loss_val)\n","              acc_vals.append(acc_val)\n","              y_pred_all[iteration-1 , epoch] =  y_pred_sample\n","\n","              print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n","                        iteration, n_iterations_validation,\n","                        iteration * 100 / n_iterations_validation),\n","                    end=\" \" * 10)\n","              \n","          loss_val = np.mean(loss_vals)\n","          acc_val = np.mean(acc_vals)\n","\n","          print(\"\\rEpoch: {}  Train accuracy: {:.4f}%  Loss_train: {:.6f}  Val accuracy: {:.4f}%  Loss_test: {:.6f}{}\".format(\n","              epoch + 1, np.mean(acc_train)*100,np.mean(loss_train),acc_val * 100, loss_val,\n","              \" (improved)\" if loss_val < best_loss_val else \"\"))\n","\n","          loss_tests.append(loss_val) #**\n","          acc_tests.append(acc_val) #**\n","\n","          #print(np.mean(loss_trains)) #**        \n","          \n","\n","          #**\n","          np.savetxt(checkpoint_path+\"loss_tr.csv\", loss_trains, delimiter=\",\")\n","          np.savetxt(checkpoint_path+\"loss_te.csv\", loss_tests, delimiter=\",\")\n","          np.savetxt(checkpoint_path+\"acc_tr.csv\", acc_trains, delimiter=\",\")\n","          np.savetxt(checkpoint_path+\"acc_te.csv\", acc_tests, delimiter=\",\")\n","\n","          # Save model all the time\n","          save_path = saver.save(sess, checkpoint_path)\n","\n","          with open(checkpoint_path + 'OtherVars', 'wb') as f:\n","              start_epoch = epoch\n","              pickle.dump([acc_trains, loss_trains, acc_tests, loss_tests ,time_per_epochs, start_epoch,y_pred_all], f)\n","          "],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-49-57ef6f08c5e1>:29: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","\n","Check point not loaded\n","\n","Iteration: 1771/1771 (100.0%)  Loss: 0.06024\n","Elapsed: 58.9\n","Estimated remaining time: 0.3 hours\n","Epoch: 1  Train accuracy: 91.8859%  Loss_train: 0.081450  Val accuracy: 97.9675%  Loss_test: 0.017640 (improved)\n","Iteration: 1771/1771 (100.0%)  Loss: 0.00792\n","Elapsed: 50.8\n","Estimated remaining time: 0.3 hours\n","Epoch: 2  Train accuracy: 98.6222%  Loss_train: 0.021639  Val accuracy: 98.9837%  Loss_test: 0.009415 (improved)\n","Iteration: 1771/1771 (100.0%)  Loss: 0.03701\n","Elapsed: 50.3\n","Estimated remaining time: 0.3 hours\n","Epoch: 3  Train accuracy: 96.0136%  Loss_train: 0.027229  Val accuracy: 99.5935%  Loss_test: 0.042576 (improved)\n","Iteration: 1771/1771 (100.0%)  Loss: 0.04341\n","Elapsed: 50.3\n","Estimated remaining time: 0.2 hours\n","Epoch: 4  Train accuracy: 99.3394%  Loss_train: 0.020477  Val accuracy: 99.4919%  Loss_test: 0.007028 (improved)\n","Iteration: 1771/1771 (100.0%)  Loss: 0.03772\n","Elapsed: 50.6\n","Estimated remaining time: 0.2 hours\n","Epoch: 5  Train accuracy: 99.8532%  Loss_train: 0.005366  Val accuracy: 99.7967%  Loss_test: 0.011310 (improved)\n","Iteration: 1771/1771 (100.0%)  Loss: 0.00354\n","Elapsed: 50.3\n","Estimated remaining time: 0.2 hours\n","Epoch: 6  Train accuracy: 99.5934%  Loss_train: 0.013420  Val accuracy: 99.8476%  Loss_test: 0.001858 (improved)\n","Iteration: 1771/1771 (100.0%)  Loss: 0.00746\n","Elapsed: 50.2\n","Estimated remaining time: 0.2 hours\n","Epoch: 7  Train accuracy: 99.3732%  Loss_train: 0.015394  Val accuracy: 99.5427%  Loss_test: 0.006278 (improved)\n","Iteration: 1771/1771 (100.0%)  Loss: 0.00433\n","Elapsed: 49.7\n","Estimated remaining time: 0.2 hours\n","Epoch: 8  Train accuracy: 99.7911%  Loss_train: 0.011401  Val accuracy: 99.7459%  Loss_test: 0.007836 (improved)\n","Iteration: 1771/1771 (100.0%)  Loss: 0.00617\n","Elapsed: 50.3\n","Estimated remaining time: 0.2 hours\n","Epoch: 9  Train accuracy: 99.8758%  Loss_train: 0.008686  Val accuracy: 99.8476%  Loss_test: 0.001857 (improved)\n","Iteration: 1771/1771 (100.0%)  Loss: 0.00145\n","Elapsed: 49.9\n","Estimated remaining time: 0.2 hours\n","Epoch: 10  Train accuracy: 99.7515%  Loss_train: 0.011549  Val accuracy: 99.3902%  Loss_test: 0.113838 (improved)\n","Iteration: 1771/1771 (100.0%)  Loss: 0.00315\n","Elapsed: 49.6\n","Estimated remaining time: 0.1 hours\n","Epoch: 11  Train accuracy: 99.5483%  Loss_train: 0.009794  Val accuracy: 99.8476%  Loss_test: 0.002544 (improved)\n","Iteration: 1771/1771 (100.0%)  Loss: 0.00843\n","Elapsed: 49.5\n","Estimated remaining time: 0.1 hours\n","Epoch: 12  Train accuracy: 99.9605%  Loss_train: 0.005898  Val accuracy: 99.8984%  Loss_test: 0.002024 (improved)\n","Iteration: 1771/1771 (100.0%)  Loss: 0.00635\n","Elapsed: 49.7\n","Estimated remaining time: 0.1 hours\n","Epoch: 13  Train accuracy: 99.8645%  Loss_train: 0.009931  Val accuracy: 99.8984%  Loss_test: 0.001502 (improved)\n","Iteration: 1771/1771 (100.0%)  Loss: 0.00021\n","Elapsed: 49.8\n","Estimated remaining time: 0.1 hours\n","Epoch: 14  Train accuracy: 99.9831%  Loss_train: 0.002703  Val accuracy: 99.7967%  Loss_test: 0.002168 (improved)\n","Iteration: 1771/1771 (100.0%)  Loss: 0.00239\n","Elapsed: 49.7\n","Estimated remaining time: 0.1 hours\n","Epoch: 15  Train accuracy: 99.9831%  Loss_train: 0.006406  Val accuracy: 99.9492%  Loss_test: 0.021972 (improved)\n","Iteration: 1771/1771 (100.0%)  Loss: 0.00520\n","Elapsed: 49.7\n","Estimated remaining time: 0.1 hours\n","Epoch: 16  Train accuracy: 99.9887%  Loss_train: 0.003802  Val accuracy: 99.9492%  Loss_test: 0.036210 (improved)\n","Iteration: 1771/1771 (100.0%)  Loss: 0.00020\n","Elapsed: 49.7\n","Estimated remaining time: 0.1 hours\n","Epoch: 17  Train accuracy: 99.8758%  Loss_train: 0.004435  Val accuracy: 99.8984%  Loss_test: 0.001423 (improved)\n","Iteration: 1771/1771 (100.0%)  Loss: 0.00032\n","Elapsed: 49.4\n","Estimated remaining time: 0.0 hours\n","Epoch: 18  Train accuracy: 99.9209%  Loss_train: 0.010153  Val accuracy: 99.7967%  Loss_test: 0.002635 (improved)\n","Iteration: 1771/1771 (100.0%)  Loss: 0.00016\n","Elapsed: 49.3\n","Estimated remaining time: 0.0 hours\n","Epoch: 19  Train accuracy: 99.9718%  Loss_train: 0.004788  Val accuracy: 99.8984%  Loss_test: 0.001587 (improved)\n","Iteration: 1771/1771 (100.0%)  Loss: 0.00196\n","Elapsed: 49.6\n","Estimated remaining time: 0.0 hours\n","Epoch: 20  Train accuracy: 99.9661%  Loss_train: 0.001917  Val accuracy: 99.9492%  Loss_test: 0.000910 (improved)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KC8a7PzJcTUy"},"source":["# print(confusion_matrix(Test_label, y_pred_all[:,epoch]))\n","# print(classification_report(Test_label, y_pred_all[:,epoch]))\n"],"execution_count":null,"outputs":[]}]}